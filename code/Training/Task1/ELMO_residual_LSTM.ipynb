{"cells":[{"cell_type":"markdown","metadata":{"id":"FBAx6U5uneSO"},"source":["## Collab Notebook"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25991,"status":"ok","timestamp":1704575639579,"user":{"displayName":"Rebeka Angyal","userId":"14722369496259048362"},"user_tz":-60},"id":"pKSz1h4WTI5s","outputId":"f4e160f0-be42-4c3c-e6fb-f1140cc33ef4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["# Mount the drive\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# This earlier version has to be used, otherwise it doesn't work with hub.Model anymore\n","!pip install tensorflow-hub==0.15.0"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15272,"status":"ok","timestamp":1704575687913,"user":{"displayName":"Rebeka Angyal","userId":"14722369496259048362"},"user_tz":-60},"id":"hGkq0mBiTNhd","outputId":"afde9341-52af-46c0-abc0-e9396716c998"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n","  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-gdlg29si\n","  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-gdlg29si\n","  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 0d2ab99cccbbc682722e708515fe9c4cfc50185a\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: NVCCPlugin\n","  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4716 sha256=75152dafaaed35fd585d50c59dd44bc038268bd829e85a044b476c7b2870ad7a\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-yauq000f/wheels/a8/b9/18/23f8ef71ceb0f63297dd1903aedd067e6243a68ea756d6feea\n","Successfully built NVCCPlugin\n","Installing collected packages: NVCCPlugin\n","Successfully installed NVCCPlugin-0.0.2\n","created output directory at /content/src\n","Out bin /content/result.out\n"]}],"source":["import pandas as pd\n","import numpy as np\n","from scipy.special import softmax\n","from sklearn.metrics import classification_report\n","from keras.preprocessing.sequence import pad_sequences\n","PATH = 'drive/My Drive/Seq_Classification/'\n","\n","!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git\n","%load_ext nvcc4jupyter"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":1717,"status":"ok","timestamp":1704575707086,"user":{"displayName":"Rebeka Angyal","userId":"14722369496259048362"},"user_tz":-60},"id":"Eteib1lMYTs0"},"outputs":[],"source":["data = pd.read_csv('drive/My Drive/Inclusion_Exclusion_Phrase_Mining/data/Task1.csv')\n","data = data.rename(columns={'id':'Sentence #'})\n","data = data.drop('Unnamed: 0',axis=1)\n","data = data.fillna(method=\"ffill\")"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":590,"status":"ok","timestamp":1704575723105,"user":{"displayName":"Rebeka Angyal","userId":"14722369496259048362"},"user_tz":-60},"id":"BUfc443cYXH6"},"outputs":[],"source":["from keras.utils import to_categorical\n","from sklearn.model_selection import train_test_split\n","\n","class SentenceGetter(object):\n","\n","    def __init__(self, data):\n","        self.n_sent = 1\n","        self.data = data\n","        self.empty = False\n","        agg_func = lambda s: [(w, t) for w, t in zip(s[\"words\"].values.tolist(),\n","                                                           s[\"labels\"].values.tolist())]\n","        self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n","        self.sentences = [s for s in self.grouped]\n","\n","    def get_next(self):\n","        try:\n","            s = self.grouped[self.n_sent]\n","            self.n_sent += 1\n","            return s\n","        except:\n","            return None\n","\n","\n","words = list(set(data[\"words\"].values))\n","tags = ['O','B_INC','INC','B_EXC','EXC']\n","# tags = list(set(data[\"labels\"].values))\n","n_words = len(words)\n","n_tags = len(tags)\n","\n","getter = SentenceGetter(data)\n","sentences = getter.sentences\n","\n","word2idx = {w: i + 1 for i, w in enumerate(words)}\n","tag2idx = {t: i for i, t in enumerate(tags)}\n","max_len = 170\n","X = [[w[0] for w in s] for s in sentences]\n","# X = pad_sequences(maxlen=max_len, sequences=X, padding=\"post\", value='_PAD_')\n","new_X = []\n","for seq in X:\n","    new_seq = []\n","    for i in range(max_len):\n","        try:\n","            new_seq.append(seq[i])\n","        except:\n","            new_seq.append(\"__PAD__\")\n","    new_X.append(new_seq)\n","X = new_X\n","y = [np.array([tag2idx[w[1]] for w in s]) for s in sentences]\n","y = pad_sequences(maxlen=max_len, sequences=y, padding=\"post\", value=tag2idx[\"O\"])\n","# y = np.array([to_categorical(i, num_classes=n_tags) for i in y])\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15)\n","y_train = y_train.reshape(y_train.shape[0], y_train.shape[1], 1)\n"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":830,"status":"ok","timestamp":1704575725696,"user":{"displayName":"Rebeka Angyal","userId":"14722369496259048362"},"user_tz":-60},"id":"cSoJO1IoYfc5"},"outputs":[],"source":["import tensorflow as tf\n","import tensorflow_hub as hub\n","from keras import backend as K"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":1184,"status":"ok","timestamp":1704575728204,"user":{"displayName":"Rebeka Angyal","userId":"14722369496259048362"},"user_tz":-60},"id":"b5RknrC2YfkV"},"outputs":[],"source":["tf.compat.v1.disable_eager_execution()\n","\n","sess = tf.compat.v1.Session()\n","tf.compat.v1.keras.backend.set_session(sess)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20699,"status":"ok","timestamp":1704575748900,"user":{"displayName":"Rebeka Angyal","userId":"14722369496259048362"},"user_tz":-60},"id":"wk-zcyvLYfgi","outputId":"ff6dcdd7-30fc-46d2-9393-c56afc03056f"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/tf_should_use.py:288: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n","Instructions for updating:\n","Use `tf.global_variables_initializer` instead.\n"]}],"source":["elmo_model = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=True)\n","sess.run(tf.compat.v1.initialize_all_variables())\n","sess.run(tf.compat.v1.tables_initializer())"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10016,"status":"ok","timestamp":1704575758905,"user":{"displayName":"Rebeka Angyal","userId":"14722369496259048362"},"user_tz":-60},"id":"m9fEPYz8ZmFv","outputId":"4d400769-f214-4c1d-9974-2990b71c7486"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting git+https://www.github.com/keras-team/keras-contrib.git\n","  Cloning https://www.github.com/keras-team/keras-contrib.git to /tmp/pip-req-build-xpua9kb3\n","  Running command git clone --filter=blob:none --quiet https://www.github.com/keras-team/keras-contrib.git /tmp/pip-req-build-xpua9kb3\n","  warning: redirecting to https://github.com/keras-team/keras-contrib.git/\n","  Resolved https://www.github.com/keras-team/keras-contrib.git to commit 3fc5ef709e061416f4bc8a92ca3750c824b5d2b0\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras-contrib==2.0.8) (2.15.0)\n","Building wheels for collected packages: keras-contrib\n","  Building wheel for keras-contrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-contrib: filename=keras_contrib-2.0.8-py3-none-any.whl size=101055 sha256=1071429c25e9c91ecb713ac114843fd2ab82871dfae77929ce3173b3c55bb0e0\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-x5jm8kt5/wheels/74/d5/f7/0245af7ac33d5b0c2e095688649916e4bf9a8d6b3362a849f5\n","Successfully built keras-contrib\n","Installing collected packages: keras-contrib\n","Successfully installed keras-contrib-2.0.8\n"]}],"source":["!pip install git+https://www.github.com/keras-team/keras-contrib.git"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1704575796760,"user":{"displayName":"Rebeka Angyal","userId":"14722369496259048362"},"user_tz":-60},"id":"QKl8vRfdZlz-"},"outputs":[],"source":["from keras.models import Model\n","from keras import Input\n","from keras.layers import add\n","from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Lambda\n","\n","tags = ['O','B_INC','INC','B_EXC','EXC']\n","tag2idx = {t: i for i, t in enumerate(tags)}\n","\n","def write_results(result,file,ign):\n","    print(\"Writing the results for {} token\".format(ign))\n","    idx2tag = {i: w for w, i in tag2idx.items()}\n","    with open(file,'w+') as f:\n","        for i,lis in enumerate(result):\n","            line = \"\"\n","            for el in lis:\n","                tag = idx2tag[el]\n","                if tag in ['O',ign,'B_'+ign]:\n","                    line += \"O \"\n","                elif tag[0] == 'B':\n","                    line += 'B '\n","                else:\n","                    line += 'I '\n","            f.write(line+'\\n')\n","\n","\n","batch_size = 32\n","\n","def ElmoEmbedding(x):\n","    return elmo_model(inputs={\n","                            \"tokens\": tf.squeeze(tf.cast(x, tf.string)),\n","                            \"sequence_len\": tf.constant(batch_size*[max_len])\n","                      },\n","                      signature=\"tokens\",\n","                      as_dict=True)[\"elmo\"]\n","def lstm_elmo():\n","  input_text = Input(shape=(max_len,), dtype=tf.string)\n","  embedding = Lambda(ElmoEmbedding, output_shape=(None, 1024))(input_text)\n","  x = Bidirectional(LSTM(units=300, return_sequences=True,\n","                        recurrent_dropout=0.2, dropout=0.2))(embedding)\n","  x_rnn = Bidirectional(LSTM(units=300, return_sequences=True,\n","                            recurrent_dropout=0.2, dropout=0.2))(x)\n","  x = add([x, x_rnn])  # residual connection to the first biLSTM\n","  out = TimeDistributed(Dense(n_tags, activation=\"softmax\"))(x)\n","\n","  model = Model(input_text, out)\n","  model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n","  model.summary()\n","  return model\n"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1155519,"status":"ok","timestamp":1704576957252,"user":{"displayName":"Rebeka Angyal","userId":"14722369496259048362"},"user_tz":-60},"id":"d0_UkdcJaZRK","outputId":"36890236-0f3b-4c5e-a127-86977c7c442e"},"outputs":[{"name":"stdout","output_type":"stream","text":["57\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"]},{"name":"stdout","output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                Output Shape                 Param #   Connected to                  \n","==================================================================================================\n"," input_1 (InputLayer)        [(None, 170)]                0         []                            \n","                                                                                                  \n"," lambda (Lambda)             (32, None, 1024)             0         ['input_1[0][0]']             \n","                                                                                                  \n"," bidirectional (Bidirection  (32, None, 600)              3180000   ['lambda[0][0]']              \n"," al)                                                                                              \n","                                                                                                  \n"," bidirectional_1 (Bidirecti  (32, None, 600)              2162400   ['bidirectional[0][0]']       \n"," onal)                                                                                            \n","                                                                                                  \n"," add (Add)                   (32, None, 600)              0         ['bidirectional[0][0]',       \n","                                                                     'bidirectional_1[0][0]']     \n","                                                                                                  \n"," time_distributed (TimeDist  (32, None, 5)                3005      ['add[0][0]']                 \n"," ributed)                                                                                         \n","                                                                                                  \n","==================================================================================================\n","Total params: 5345405 (20.39 MB)\n","Trainable params: 5345405 (20.39 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","__________________________________________________________________________________________________\n","Train on 1824 samples\n","Epoch 1/10\n","1824/1824 [==============================] - 141s 77ms/sample - loss: 0.1521 - accuracy: 0.9449\n","Epoch 2/10\n","1824/1824 [==============================] - 114s 63ms/sample - loss: 0.0856 - accuracy: 0.9687\n","Epoch 3/10\n","1824/1824 [==============================] - 110s 60ms/sample - loss: 0.0769 - accuracy: 0.9715\n","Epoch 4/10\n","1824/1824 [==============================] - 109s 60ms/sample - loss: 0.0661 - accuracy: 0.9751\n","Epoch 5/10\n","1824/1824 [==============================] - 110s 60ms/sample - loss: 0.0573 - accuracy: 0.9789\n","Epoch 6/10\n","1824/1824 [==============================] - 110s 60ms/sample - loss: 0.0484 - accuracy: 0.9818\n","Epoch 7/10\n","1824/1824 [==============================] - 109s 60ms/sample - loss: 0.0383 - accuracy: 0.9860\n","Epoch 8/10\n","1824/1824 [==============================] - 109s 60ms/sample - loss: 0.0321 - accuracy: 0.9880\n","Epoch 9/10\n","1824/1824 [==============================] - 110s 60ms/sample - loss: 0.0269 - accuracy: 0.9901\n","Epoch 10/10\n","1824/1824 [==============================] - 111s 61ms/sample - loss: 0.0207 - accuracy: 0.9922\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n","  updates=self.state_updates,\n"]}],"source":["total = int(len(X_train)/batch_size)\n","train_split = int(total*1)\n","val_split = total - train_split\n","print(train_split)\n","X_tr, X_val = X_train[:train_split*batch_size], X_train[-val_split*batch_size:]\n","y_tr, y_val = y_train[:train_split*batch_size], y_train[-val_split*batch_size:]\n","# y_train = y_train.reshape(y_tr.shape[0], y_tr.shape[1], 1)\n","\n","lstm = lstm_elmo()\n","lstm.fit(np.array(X_tr),y_tr,epochs=10,verbose=1,batch_size=32)\n","out = lstm.predict(np.array(X_test[0:320]))\n","pred = np.argmax(out,2)\n","labels = y_test[0:320]"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":712,"status":"ok","timestamp":1704577094304,"user":{"displayName":"Rebeka Angyal","userId":"14722369496259048362"},"user_tz":-60},"id":"qMXFnYY6aZYT","outputId":"6a06e6f0-b38c-4d11-9194-8b5ebf9f536c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Writing the results for EXC token\n","Writing the results for EXC token\n"]}],"source":["write_results(pred,'drive/My Drive/Inclusion_Exclusion_Phrase_Mining/code/Training/Task1/pred.txt','EXC')\n","write_results(labels,'drive/My Drive/Inclusion_Exclusion_Phrase_Mining/code/Training/Task1/labels.txt','EXC')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qU6db445neSi"},"outputs":[],"source":["## Save the results for one token and run the next cell to get the metrics"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7705,"status":"ok","timestamp":1704577105840,"user":{"displayName":"Rebeka Angyal","userId":"14722369496259048362"},"user_tz":-60},"id":"p1Hrh4hGYfTp","outputId":"ecb5aaad-8aa8-42b3-a372-7fb20b1b626d"},"outputs":[{"name":"stdout","output_type":"stream","text":["0.539195 0.596491\n","0.57407 0.742857\n","0.556086 0.661677\n","\n"]}],"source":["#@title Calculate Metrics\n","#cpp code\n","%%cuda\n","\n","#include<bits/stdc++.h>\n","\n","using namespace std;\n","\n","struct Res\n","{\n","    vector<double> vec[3];\n","};\n","\n","Res testSequential(vector<vector<string> > &sents,\n","                                         vector<vector<string> > &labels) {\n","  uint nExprPredicted = 0;\n","  double nExprPredictedCorrectly = 0;\n","  uint nExprTrue = 0;\n","  double precNumerProp = 0, precNumerBin = 0;\n","  double recallNumerProp = 0, recallNumerBin = 0;\n","  for (uint i=0; i<sents.size(); i++) { // per sentence\n","    vector<string> labelsPredicted;\n","    // forward(sents[i]);\n","\n","    for (uint j=0; j<sents[i].size(); j++) {\n","        labelsPredicted.push_back(sents[i][j]);\n","    }\n","    // assert(labelsPredicted.size() == y.cols());\n","\n","\n","    string y, t, py=\"\", pt=\"\";\n","    uint match = 0;\n","    uint exprSize = 0;\n","    vector<pair<uint,uint> > pred, tru;\n","    int l1=-1, l2=-1;\n","\n","    if (labels[i].size() != labelsPredicted.size())\n","      cout << labels[i].size() << \" \" << labelsPredicted.size() << endl;\n","    for (uint j=0; j<labels[i].size(); j++) { // per token in a sentence\n","      t = labels[i][j];\n","      y = labelsPredicted[j];\n","\n","      if (t == \"B\") {\n","        //nExprTrue++;\n","        if (l1 != -1)\n","          tru.push_back(make_pair(l1,j));\n","        l1 = j;\n","      } else if (t == \"I\") {\n","        // cout<<\"Sentence: \"<<i<<\" Index: \"<<j<<endl;\n","        ;\n","        // assert(l1 != -1);\n","      } else if (t == \"O\") {\n","        if (l1 != -1)\n","          tru.push_back(make_pair(l1,j));\n","        l1 = -1;\n","      } else{\n","          cout<<t<<endl;\n","        assert(false);\n","      }\n","      if ((y == \"B\") || ((y == \"I\") && ((py == \"\") || (py == \"O\")))) {\n","        nExprPredicted++;\n","        if (l2 != -1)\n","          pred.push_back(make_pair(l2,j));\n","        l2 = j;\n","      } else if (y == \"I\") {\n","        assert(l2 != -1);\n","      } else if (y == \"O\") {\n","        if (l2 != -1)\n","          pred.push_back(make_pair(l2,j));\n","        l2 = -1;\n","      } else {\n","        cout << y << endl;\n","        assert(false);\n","      }\n","\n","      py = y;\n","      pt = t;\n","    }\n","    if ((l1 != -1) && (l1 != labels[i].size()))\n","      tru.push_back(make_pair(l1,labels[i].size()));\n","    if ((l2 != -1) && (l2 != labels[i].size()))\n","      pred.push_back(make_pair(l2,labels[i].size()));\n","\n","    vector<bool> trum = vector<bool>(tru.size(),false);\n","      vector<bool> predm = vector<bool>(pred.size(),false);\n","    for (uint a=0; a<tru.size(); a++) {\n","      pair<uint,uint> truSpan = tru[a];\n","      nExprTrue++;\n","      for (uint b=0; b<pred.size(); b++) {\n","        pair<uint,uint> predSpan = pred[b];\n","\n","        uint lmax, rmin;\n","        if (truSpan.first > predSpan.first)\n","          lmax = truSpan.first;\n","        else\n","          lmax = predSpan.first;\n","        if (truSpan.second < predSpan.second)\n","          rmin = truSpan.second;\n","        else\n","          rmin = predSpan.second;\n","\n","        uint overlap = 0;\n","        if (rmin > lmax)\n","          overlap = rmin-lmax;\n","        if (predSpan.second == predSpan.first) cout << predSpan.first << endl;\n","        assert(predSpan.second != predSpan.first);\n","        precNumerProp += (double)overlap/(predSpan.second-predSpan.first);\n","        recallNumerProp += (double)overlap/(truSpan.second-truSpan.first);\n","        if (!predm[b] && overlap > 0) {\n","          precNumerBin += (double)(overlap>0);\n","          predm[b] = true;\n","        }\n","        if (!trum[a] && overlap>0) {\n","          recallNumerBin += 1;\n","          trum[a]=true;\n","        }\n","      }\n","    }\n","\n","  }\n","  double precisionProp = (nExprPredicted==0) ? 1 : precNumerProp/nExprPredicted;\n","  double recallProp = recallNumerProp/nExprTrue;\n","  double f1Prop = (2*precisionProp*recallProp)/(precisionProp+recallProp);\n","  double precisionBin = (nExprPredicted==0) ? 1 : precNumerBin/nExprPredicted;\n","  double recallBin = recallNumerBin/nExprTrue;\n","  double f1Bin = (2*precisionBin*recallBin)/(precisionBin+recallBin);\n","\n","  Res results;\n","  results.vec[0].push_back(precisionProp); results.vec[0].push_back(precisionBin);\n","  results.vec[1].push_back(recallProp); results.vec[1].push_back(recallBin);\n","  results.vec[2].push_back(f1Prop); results.vec[2].push_back(f1Bin);\n","  return results;\n","}\n","\n","\n","int main()\n","{\n","    vector<vector<string> > pred;\n","    vector<vector<string> > labels;\n","\n","    std::ifstream file(\"drive/My Drive/Inclusion_Exclusion_Phrase_Mining/code/Training/Task1/pred.txt\");\n","    if (file.is_open()) {\n","        std::string line;\n","        while (std::getline(file, line))\n","        {\n","            // using printf() in all tests for consistency\n","            vector<string> temp;\n","            for(int i=0;i<line.length();i+=2)\n","            {\n","                string tag(1,line[i]);\n","                temp.push_back(tag);\n","            }\n","            pred.push_back(temp);\n","        }\n","        file.close();\n","    }\n","\n","\n","    std::ifstream file1(\"drive/My Drive/Inclusion_Exclusion_Phrase_Mining/code/Training/Task1/labels.txt\");\n","    if (file1.is_open()) {\n","        std::string line;\n","        while (std::getline(file1, line))\n","        {\n","            // using printf() in all tests for consistency\n","            vector<string> temp;\n","            for(int i=0;i<line.length();i+=2)\n","            {\n","                string tag(1,line[i]);\n","                temp.push_back(tag);\n","            }\n","            labels.push_back(temp);\n","        }\n","        file1.close();\n","    }\n","\n","    // for(int i=0;i<pred.size();i++)\n","    // {\n","    //     for(int j=0;j<pred[i].size();j++)\n","    //         cout<<pred[i][j];\n","    //     cout<<endl;\n","    // }\n","    // for(int i=0;i<labels.size();i++)\n","    // {\n","    //     for(int j=0;j<labels[i].size();j++)\n","    //         cout<<labels[i][j];\n","    //     cout<<endl;\n","    // }\n","\n","    Res result = testSequential(pred,labels);\n","\n","    cout<<result.vec[0][0]<<\" \"<<result.vec[0][1]<<endl;\n","    cout<<result.vec[1][0]<<\" \"<<result.vec[1][1]<<endl;\n","    cout<<result.vec[2][0]<<\" \"<<result.vec[2][1]<<endl;\n","    return 0;\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XA4rg86EtHSB"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"}},"nbformat":4,"nbformat_minor":0}
