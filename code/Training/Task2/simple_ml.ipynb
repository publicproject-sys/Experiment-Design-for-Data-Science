{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bk9BUST3Kh8_"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pwjv9OqzKmQN"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../../../data/Task2.csv', index_col='sentence_id')\n",
    "data = data.rename(columns={'id':'Sentence #'})\n",
    "data = data.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "atBwLwHoKzSb"
   },
   "outputs": [],
   "source": [
    "sentences = []\n",
    "labels = list(data['type']) \n",
    "typs = data['type'].values\n",
    "\n",
    "x = data.apply(lambda l: sentences.append(l['sentence'].split(' ')),axis=1)\n",
    "words = []\n",
    "for sent in sentences:\n",
    "    for wrd in sent:\n",
    "        words.append(wrd)\n",
    "words = list(set(words))\n",
    "tags = list(set(labels))\n",
    "\n",
    "n_words = len(words)\n",
    "n_tags = len(tags)\n",
    "word2idx = {w: i + 1 for i, w in enumerate(words)}\n",
    "tag2idx = {t: i for i, t in enumerate(tags)}\n",
    "max_len = 30\n",
    "X = [[word2idx[w] for w in s] for s in sentences]    \n",
    "X = pad_sequences(maxlen=max_len, sequences=X, padding=\"post\", value=0)\n",
    "y = [tag2idx[tg] for tg in labels]\n",
    "# y = pad_sequences(maxlen=max_len, sequences=y, padding=\"post\", value=tag2idx[\"O\"])\n",
    "y = np.array([to_categorical(i, num_classes=n_tags) for i in y])\n",
    "y = [[y[i],typs[i]] for i in range(len(y))]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "y_train = np.array([lab[0] for lab in y_train])\n",
    "typ_test = [lab[1] for lab in y_test]\n",
    "y_test = np.array([lab[0] for lab  in y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mt3HKUwALKN0"
   },
   "outputs": [],
   "source": [
    "clf = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 483
    },
    "colab_type": "code",
    "id": "lrnOTxBnLg6U",
    "outputId": "73883154-d5b2-4708-e995-b7cda485eed8"
   },
   "outputs": [],
   "source": [
    "clf.fit(X_train,y_train)\n",
    "pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 985
    },
    "colab_type": "code",
    "id": "1xkGXDdRMb1v",
    "outputId": "10e631a7-ff40-4c32-d842-3997b24a849c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For inclusions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/artur/Uni/2023W/188.992 Experiment Design for Data Science/ExpDesign_Exercise2/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/artur/Uni/2023W/188.992 Experiment Design for Data Science/ExpDesign_Exercise2/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.628205</td>\n",
       "      <td>0.771654</td>\n",
       "      <td>234.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro avg</th>\n",
       "      <td>0.615063</td>\n",
       "      <td>0.628205</td>\n",
       "      <td>0.621564</td>\n",
       "      <td>234.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.314103</td>\n",
       "      <td>0.385827</td>\n",
       "      <td>234.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.628205</td>\n",
       "      <td>0.771654</td>\n",
       "      <td>234.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samples avg</th>\n",
       "      <td>0.600427</td>\n",
       "      <td>0.628205</td>\n",
       "      <td>0.609687</td>\n",
       "      <td>234.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score  support\n",
       "0              1.000000  0.628205  0.771654    234.0\n",
       "1              0.000000  0.000000  0.000000      0.0\n",
       "micro avg      0.615063  0.628205  0.621564    234.0\n",
       "macro avg      0.500000  0.314103  0.385827    234.0\n",
       "weighted avg   1.000000  0.628205  0.771654    234.0\n",
       "samples avg    0.600427  0.628205  0.609687    234.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For exclusions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/artur/Uni/2023W/188.992 Experiment Design for Data Science/ExpDesign_Exercise2/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/artur/Uni/2023W/188.992 Experiment Design for Data Science/ExpDesign_Exercise2/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.577093</td>\n",
       "      <td>0.731844</td>\n",
       "      <td>227.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro avg</th>\n",
       "      <td>0.592760</td>\n",
       "      <td>0.577093</td>\n",
       "      <td>0.584821</td>\n",
       "      <td>227.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.288546</td>\n",
       "      <td>0.365922</td>\n",
       "      <td>227.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.577093</td>\n",
       "      <td>0.731844</td>\n",
       "      <td>227.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samples avg</th>\n",
       "      <td>0.570485</td>\n",
       "      <td>0.577093</td>\n",
       "      <td>0.572687</td>\n",
       "      <td>227.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score  support\n",
       "0              0.000000  0.000000  0.000000      0.0\n",
       "1              1.000000  0.577093  0.731844    227.0\n",
       "micro avg      0.592760  0.577093  0.584821    227.0\n",
       "macro avg      0.500000  0.288546  0.365922    227.0\n",
       "weighted avg   1.000000  0.577093  0.731844    227.0\n",
       "samples avg    0.570485  0.577093  0.572687    227.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inc_test = []\n",
    "exc_test = []\n",
    "inc_pred = []\n",
    "exc_pred = []\n",
    "for i,t in enumerate(typ_test):\n",
    "    if t == 'I':\n",
    "        inc_test.append(y_test[i])\n",
    "        inc_pred.append(pred[i])\n",
    "    else:\n",
    "        exc_test.append(y_test[i])\n",
    "        exc_pred.append(pred[i])\n",
    "print(\"For inclusions\")\n",
    "report = classification_report(inc_test,inc_pred,output_dict=True)\n",
    "df = pd.DataFrame(report).transpose()\n",
    "display(df)\n",
    "print(\"For exclusions\")\n",
    "report = classification_report(exc_test,exc_pred,output_dict=True)\n",
    "df = pd.DataFrame(report).transpose()\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000 words loaded!\n"
     ]
    }
   ],
   "source": [
    "def loadGloveModel(File):\n",
    "    with open(File, 'r', encoding='utf-8') as f:\n",
    "        gloveModel = {}\n",
    "        for line in f:\n",
    "            splitLines = line.split()\n",
    "            word = splitLines[0]\n",
    "            wordEmbedding = np.array([float(val) for val in splitLines[1:]])\n",
    "            gloveModel[word] = wordEmbedding\n",
    "    print(len(gloveModel), \"words loaded!\")\n",
    "    return gloveModel\n",
    "\n",
    "vec_model = loadGloveModel('glove/glove.6B.300d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag2idx = {t: i for i, t in enumerate(tags)}\n",
    "max_len = 30\n",
    "emb_dim = len(vec_model['the'])\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for sent in sentences:\n",
    "    vec = np.zeros((30,emb_dim))\n",
    "    for i, word in enumerate(sent):\n",
    "        if word in vec_model:\n",
    "            vec[i,:] = vec_model[word]\n",
    "    X.append(vec)\n",
    "X = np.array(X)\n",
    "y = np.array([tag2idx[tg] for tg in labels])\n",
    "y = [[y[i],typs[i]] for i in range(len(y))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "y_train = np.array([lab[0] for lab in y_train])\n",
    "typ_test = [lab[1] for lab in y_test]\n",
    "y_test = np.array([lab[0] for lab  in y_test])\n",
    "X_train = X_train.reshape((X_train.shape[0],max_len*emb_dim))\n",
    "X_test = X_test.reshape((X_test.shape[0],max_len*emb_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_results(y_test,pred):\n",
    "    \n",
    "    report = classification_report(y_test,pred.flatten('F'),output_dict=True)\n",
    "    df = pd.DataFrame(report).transpose()\n",
    "    display(df)\n",
    "    \n",
    "    inc_test = []\n",
    "    exc_test = []\n",
    "    inc_pred = []\n",
    "    exc_pred = []\n",
    "    for i,t in enumerate(typ_test):\n",
    "        if t == 'I':\n",
    "            inc_test.append(y_test[i])\n",
    "            inc_pred.append(pred[i])\n",
    "        else:\n",
    "            exc_test.append(y_test[i])\n",
    "            exc_pred.append(pred[i])\n",
    "    print(\"For inclusions\")\n",
    "    report = classification_report(inc_test,inc_pred,output_dict=True)\n",
    "    df = pd.DataFrame(report).transpose()\n",
    "    display(df)\n",
    "    print(\"For exclusions\")\n",
    "    report = classification_report(exc_test,exc_pred,output_dict=True)\n",
    "    df = pd.DataFrame(report).transpose()\n",
    "    display(df)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.721805</td>\n",
       "      <td>232.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.751553</td>\n",
       "      <td>0.528384</td>\n",
       "      <td>0.620513</td>\n",
       "      <td>229.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.678959</td>\n",
       "      <td>0.678959</td>\n",
       "      <td>0.678959</td>\n",
       "      <td>0.678959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.695776</td>\n",
       "      <td>0.677985</td>\n",
       "      <td>0.671159</td>\n",
       "      <td>461.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.695413</td>\n",
       "      <td>0.678959</td>\n",
       "      <td>0.671488</td>\n",
       "      <td>461.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "0              0.640000  0.827586  0.721805  232.000000\n",
       "1              0.751553  0.528384  0.620513  229.000000\n",
       "accuracy       0.678959  0.678959  0.678959    0.678959\n",
       "macro avg      0.695776  0.677985  0.671159  461.000000\n",
       "weighted avg   0.695413  0.678959  0.671488  461.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For inclusions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/artur/Uni/2023W/188.992 Experiment Design for Data Science/ExpDesign_Exercise2/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/artur/Uni/2023W/188.992 Experiment Design for Data Science/ExpDesign_Exercise2/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/artur/Uni/2023W/188.992 Experiment Design for Data Science/ExpDesign_Exercise2/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>232.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.827586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.413793</td>\n",
       "      <td>0.452830</td>\n",
       "      <td>232.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>232.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "0              1.000000  0.827586  0.905660  232.000000\n",
       "1              0.000000  0.000000  0.000000    0.000000\n",
       "accuracy       0.827586  0.827586  0.827586    0.827586\n",
       "macro avg      0.500000  0.413793  0.452830  232.000000\n",
       "weighted avg   1.000000  0.827586  0.905660  232.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For exclusions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/artur/Uni/2023W/188.992 Experiment Design for Data Science/ExpDesign_Exercise2/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/artur/Uni/2023W/188.992 Experiment Design for Data Science/ExpDesign_Exercise2/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/artur/Uni/2023W/188.992 Experiment Design for Data Science/ExpDesign_Exercise2/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.528384</td>\n",
       "      <td>0.691429</td>\n",
       "      <td>229.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.528384</td>\n",
       "      <td>0.528384</td>\n",
       "      <td>0.528384</td>\n",
       "      <td>0.528384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.264192</td>\n",
       "      <td>0.345714</td>\n",
       "      <td>229.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.528384</td>\n",
       "      <td>0.691429</td>\n",
       "      <td>229.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "0              0.000000  0.000000  0.000000    0.000000\n",
       "1              1.000000  0.528384  0.691429  229.000000\n",
       "accuracy       0.528384  0.528384  0.528384    0.528384\n",
       "macro avg      0.500000  0.264192  0.345714  229.000000\n",
       "weighted avg   1.000000  0.528384  0.691429  229.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf = SVC(kernel='poly')\n",
    "clf.fit(X_train,y_train)\n",
    "pred = clf.predict(X_test)\n",
    "full_results(y_test,pred)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "xgboost.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
