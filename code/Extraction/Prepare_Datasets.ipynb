{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the datasets from the annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = [] \n",
    "with open('annotations_2000.json1','r') as f: \n",
    "    for line in f.readlines():\n",
    "        annotations.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot = 0\n",
    "nothing = 0 \n",
    "valid_annotations = []\n",
    "for samp in annotations:\n",
    "    if len(samp['labels']) == 0:\n",
    "        continue\n",
    "    if samp['labels'][0][2] == 'Nothing':\n",
    "        nothing += 1\n",
    "        continue\n",
    "    valid_annotations.append(samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_initVecs(i):\n",
    "    text = valid_annotations[i]['text']\n",
    "    text = text.strip(\".\")\n",
    "    y_small = ['0' for i in range(len(text))]\n",
    "    \n",
    "    for ran in sorted(valid_annotations[i]['labels']):\n",
    "        if ran[2] == 'Inclusion':\n",
    "            arr = ['1']*(ran[1] - ran[0]+1)\n",
    "        else:\n",
    "            arr = ['2']*(ran[1]-ran[0]+1)\n",
    "        y_small[ran[0]:ran[1]+1] = arr\n",
    "\n",
    "    for i in range(len(text)):\n",
    "        if text[i] == '.': y_small[i] = '.'\n",
    "        if text[i] == \" \":y_small[i] = \" \"\n",
    "    y_string = \"\".join(y_small)\n",
    "    y_string = y_string.split('.')\n",
    "    y = []\n",
    "    sentences = text.split('.')\n",
    "    for i in range(len(sentences)):\n",
    "        if len(y_string[i]) == 0:\n",
    "            continue\n",
    "        temp = []\n",
    "        for wrd in y_string[i].split(\" \"):\n",
    "            if len(wrd) == 0:continue\n",
    "            temp.append(int(wrd[0]))\n",
    "        y.append(temp)\n",
    "    for i in range(len(sentences)):\n",
    "        sentences[i] = sentences[i].strip(' ')\n",
    "    sentences = [sent for sent in sentences if len(sent)>0]\n",
    "    return sentences, np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "sentid = -1\n",
    "for i in range(len(valid_annotations)):\n",
    "    sentences, labels = get_initVecs(i)\n",
    "    for j in range(len(sentences)):\n",
    "        if sum(labels[j])==0:\n",
    "            continue\n",
    "        sentid += 1\n",
    "        sents = sentences[j].split(\" \")\n",
    "        for k in range(len(labels[j])):\n",
    "            temp = {}\n",
    "            temp['id'] = sentid\n",
    "            temp['words'] = sents[k]\n",
    "            if labels[j][k] == 0:\n",
    "                temp['labels'] = 'O'\n",
    "            elif labels[j][k] == 1:\n",
    "                temp['labels'] = 'INC'\n",
    "            else:\n",
    "                temp['labels'] = 'EXC'\n",
    "            data.append(temp)\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(l):\n",
    "    \n",
    "    word = str(l['words'])\n",
    "    word = word.lower()\n",
    "    word = re.sub('[^a-zA-Z0-9]','',word)\n",
    "    return word\n",
    "\n",
    "df['cleaned'] = df.apply(lambda l : clean_data(l),axis=1)\n",
    "df.rename({'cleaned':'words'},axis=1,inplace=True)\n",
    "df = df[['id','words','labels']]\n",
    "df.to_csv('Task1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data for Second Level Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('Task1.csv')\n",
    "sentences = []\n",
    "cur = []\n",
    "typ = ''\n",
    "ind = 0\n",
    "\n",
    "for i,row in df.iterrows():\n",
    "    if row['labels'][0] == 'B' and len(cur):\n",
    "        cur = [str(c) for c in cur]\n",
    "        sentences.append({'id':ind,'sentence':' '.join(cur),'type':typ})\n",
    "        cur = []\n",
    "    if row['labels'] != 'O':\n",
    "        if row['labels'][0] == 'B':\n",
    "            ind = row['id']\n",
    "        if 'EXC' in row['labels']:\n",
    "            typ = 'E'\n",
    "        else:\n",
    "            typ = 'I'\n",
    "        cur.append(row['words'])\n",
    "        \n",
    "cur = [str(c) for c in cur]\n",
    "sentences.append({'id':ind,'sentence':' '.join(cur)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task2 = pd.DataFrame(sentences)\n",
    "task2.to_csv('Task2.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
